{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T14:06:42.320191Z",
     "iopub.status.busy": "2022-02-24T14:06:42.319942Z",
     "iopub.status.idle": "2022-02-24T14:06:43.080212Z",
     "shell.execute_reply": "2022-02-24T14:06:43.079671Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from logging import warning\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T14:06:43.083137Z",
     "iopub.status.busy": "2022-02-24T14:06:43.082704Z",
     "iopub.status.idle": "2022-02-24T14:06:43.086995Z",
     "shell.execute_reply": "2022-02-24T14:06:43.086511Z"
    }
   },
   "outputs": [],
   "source": [
    "IS_NOTEBOOK: bool = True  # @param {type: \"boolean\"}\n",
    "AMBIENT_OCCLUSION_MAP_FILE_NAME: str = \"ambient_occlusion.png\"  # @param {type: \"string\"}\n",
    "\n",
    "PATH_PREFIX: str = (\n",
    "    \"https://raw.githubusercontent.com/YertleTurtleGit/photometric-stereo-mappings/main/test_dataset/\"\n",
    "    if IS_NOTEBOOK\n",
    "    else \"./../test_dataset/\"\n",
    ")\n",
    "\n",
    "HEIGHT_MAP_PATH:str = PATH_PREFIX + \"output/height.png\"\n",
    "MASK_PATH = PATH_PREFIX + \"output/opacity.png\"\n",
    "\n",
    "OUTPUT_PATH = None if IS_NOTEBOOK else PATH_PREFIX + \"output/\" + AMBIENT_OCCLUSION_MAP_FILE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T14:06:43.089113Z",
     "iopub.status.busy": "2022-02-24T14:06:43.088893Z",
     "iopub.status.idle": "2022-02-24T14:06:43.096969Z",
     "shell.execute_reply": "2022-02-24T14:06:43.096466Z"
    }
   },
   "outputs": [],
   "source": [
    "def _read_image(\n",
    "    image_path: str, color: bool = True, target_dtype: np.dtype = np.dtype(\"float64\")\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Reads an image from URI and converts it to an array with specified bit depth.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The path to the image file.\n",
    "        color (bool, optional): Read image as color image. Defaults to True.\n",
    "        target_dtype (np.dtype, optional): The target bit depth. Defaults to np.dtype(\"float64\").\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The output array with shape (w,h,3) for color or (w,h) for grayscale images.\n",
    "    \"\"\"\n",
    "    image = io.imread(image_path)\n",
    "    image_dtype: np.dtype = image.dtype\n",
    "    image = image.astype(target_dtype)\n",
    "\n",
    "    if image_dtype == np.dtype(\"uint8\"):\n",
    "        image /= pow(2, 8) - 1\n",
    "    elif image_dtype == np.dtype(\"uint16\"):\n",
    "        image /= pow(2, 16) - 1\n",
    "    elif image_dtype == np.dtype(\"uint32\"):\n",
    "        image /= pow(2, 32) - 1\n",
    "\n",
    "    if color:\n",
    "        if len(image.shape) == 3:\n",
    "            return image\n",
    "        elif len(image.shape) == 2:\n",
    "            return np.array([image, image, image])\n",
    "        elif len(image.shape) == 4:\n",
    "            return np.array([image[:, :, 0], image[:, :, 1], image[:, :, 2]])\n",
    "        else:\n",
    "            warning(\n",
    "                \"Image channel count of \"\n",
    "                + str(len(image.shape))\n",
    "                + \" with shape \"\n",
    "                + str(image.shape)\n",
    "                + \" is unknown: \"\n",
    "                + image_path\n",
    "            )\n",
    "    else:\n",
    "        if len(image.shape) == 2:\n",
    "            return image\n",
    "        elif len(image.shape) == 3 or len(image.shape) == 4:\n",
    "            return (image[:, :, 0] + image[:, :, 1] + image[:, :, 2]) / 3\n",
    "        else:\n",
    "            warning(\n",
    "                \"Image channel count of \"\n",
    "                + str(len(image.shape))\n",
    "                + \" with shape \"\n",
    "                + str(image.shape)\n",
    "                + \" is unknown: \"\n",
    "                + image_path\n",
    "            )\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T14:06:43.099092Z",
     "iopub.status.busy": "2022-02-24T14:06:43.098956Z",
     "iopub.status.idle": "2022-02-24T14:06:43.103843Z",
     "shell.execute_reply": "2022-02-24T14:06:43.103358Z"
    }
   },
   "outputs": [],
   "source": [
    "def ambient_occlusion_map(height_map_path: str, output_path: str, mask_path: str):\n",
    "    \"\"\"Calculates the ambient occlusion.\n",
    "\n",
    "    Args:\n",
    "        height_map_path (str): _description_\n",
    "        output_path (str): _description_\n",
    "        mask_path (str, optional): _description_. Defaults to None.\n",
    "    \"\"\"\n",
    "    height_map = _read_image(height_map_path, color=False)\n",
    "    mask_image = _read_image(mask_path, color=False)\n",
    "\n",
    "    blurred_height_map = cv.blur(height_map, (3, 3))\n",
    "    blurred_mask = cv.blur(mask_image, (3, 3))\n",
    "\n",
    "    ambient_occlusion_map = height_map - blurred_height_map\n",
    "    ambient_occlusion_map[blurred_mask > 0] *= blurred_mask[blurred_mask > 0]\n",
    "    ambient_occlusion_map[blurred_mask < 1] *= 0.01\n",
    "\n",
    "    ambient_occlusion_map -= np.min(ambient_occlusion_map)\n",
    "    ambient_occlusion_map /= np.max(ambient_occlusion_map)\n",
    "    ambient_occlusion_map += 1\n",
    "    ambient_occlusion_map[mask_image == 0] = 0\n",
    "\n",
    "    if output_path:\n",
    "        ambient_occlusion_map = np.clip(ambient_occlusion_map * 255, 0, 255).astype(\n",
    "            \"uint8\"\n",
    "        )\n",
    "        cv.imwrite(output_path, ambient_occlusion_map)\n",
    "    else:\n",
    "        plt.imshow(ambient_occlusion_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T14:06:43.106152Z",
     "iopub.status.busy": "2022-02-24T14:06:43.105716Z",
     "iopub.status.idle": "2022-02-24T14:06:43.502114Z",
     "shell.execute_reply": "2022-02-24T14:06:43.501590Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    ambient_occlusion_map(HEIGHT_MAP_PATH, OUTPUT_PATH, MASK_PATH)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9fb47bfb27aa80605ee8bc9c35db619ba1a83d93aaa1ab9d0d517b5218a2e478"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
