{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Map Pipeline](https://github.com/YertleTurtleGit/depth-from-normals/actions/workflows/map_pipeline.yml/badge.svg)](https://github.com/YertleTurtleGit/depth-from-normals/actions/workflows/map_pipeline.yml)\n",
    "[![Lint](https://github.com/YertleTurtleGit/depth-from-normals/actions/workflows/lint.yml/badge.svg)](https://github.com/YertleTurtleGit/depth-from-normals/actions/workflows/lint.yml)\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/YertleTurtleGit/depth-from-normals\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n",
    "<!-- END doctoc generated TOC please keep comment here to allow auto update -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm estimates a 3d integral with the normal mapping with surface integrals of vector fields. First the directional gradients of the normals in x- and y-direction are calculated. They are then used to calculate the integrated values by a cumulative sum (Riemann sum). This process is repeated with differently rotated versions of the gradient mapping to average the values and reduce errors as a cumulative sum alone is very prone for subsequent errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T08:04:05.289303Z",
     "iopub.status.busy": "2022-03-21T08:04:05.289164Z",
     "iopub.status.idle": "2022-03-21T08:04:19.591044Z",
     "shell.execute_reply": "2022-03-21T08:04:19.590486Z"
    },
    "id": "qJM0ecFCGW7m"
   },
   "outputs": [],
   "source": [
    "import numpy as np  # vector matrix calculations\n",
    "import cv2 as cv  # image manipulation\n",
    "from scipy.integrate import cumulative_trapezoid, simpson  # normal map integration\n",
    "from multiprocessing.pool import ThreadPool as Pool  # optimization for shorter runtime\n",
    "from skimage import io  # image reading from url\n",
    "from math import sin, cos, radians, pi  # basic angle math\n",
    "from typing import List, Tuple  # python typing\n",
    "from matplotlib import pyplot as plt  # visualization\n",
    "from matplotlib.colors import TwoSlopeNorm  # visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T08:04:05.280324Z",
     "iopub.status.busy": "2022-03-21T08:04:05.279926Z",
     "iopub.status.idle": "2022-03-21T08:04:05.287018Z",
     "shell.execute_reply": "2022-03-21T08:04:05.286531Z"
    }
   },
   "outputs": [],
   "source": [
    "NORMAL_MAP_A_PATH: str = \"https://raw.githubusercontent.com/YertleTurtleGit/depth-from-normals/main/normal_mapping_a.png\"  # @param {type: \"string\"}\n",
    "NORMAL_MAP_B_PATH: str = \"https://raw.githubusercontent.com/YertleTurtleGit/depth-from-normals/main/normal_mapping_b.png\"\n",
    "NORMAL_MAP_A_IMAGE: np.ndarray = io.imread(NORMAL_MAP_A_PATH)\n",
    "NORMAL_MAP_B_IMAGE: np.ndarray = io.imread(NORMAL_MAP_B_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients\n",
    "\n",
    "First we calculate the anisotropic (directional) gradients from our normal map.\n",
    "\n",
    "Given the normal vector $\\vec{n} \\in \\mathbb{R}^{3}$ and a rotation value $r \\in \\mathbb{R}[0,2\\pi]$, the anisotropic gradients are calculated:\n",
    "\n",
    "$$\n",
    "a_h = \\arccos{\\vec{n_x}}, \\hspace{5px} g_l = (1 - \\sin{a_h}) * sgn(a_h - \\frac{\\pi}{2})\n",
    "$$\n",
    "\n",
    "$$\n",
    "a_v = \\arccos{\\vec{n_y}}, \\hspace{5px} g_t = (1 - \\sin{a_v}) * sgn(a_v - \\frac{\\pi}{2})\n",
    "$$\n",
    "\n",
    "This will be calculated for every pixel and for every rotation value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradients(normals: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    horizontal_angle_map = np.arccos(np.clip(normals[:, :, 0], -1, 1))\n",
    "    left_gradients = (1 - np.sin(horizontal_angle_map)) * np.sign(\n",
    "        horizontal_angle_map - pi / 2\n",
    "    )\n",
    "\n",
    "    vertical_angle_map = np.arccos(np.clip(normals[:, :, 1], -1, 1))\n",
    "    top_gradients = -(1 - np.sin(vertical_angle_map)) * np.sign(\n",
    "        vertical_angle_map - pi / 2\n",
    "    )\n",
    "\n",
    "    return left_gradients, top_gradients\n",
    "\n",
    "\n",
    "normals = ((NORMAL_MAP_A_IMAGE[:, :, :3] / 255) - 0.5) * 2\n",
    "left_gradients, top_gradients = calculate_gradients(normals)\n",
    "\n",
    "\n",
    "figsize = (14, 14)\n",
    "figure, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "axes[0].set_title(\"anisotropic left gradients (left to right)\")\n",
    "_ = axes[0].imshow(left_gradients, cmap=\"RdBu\", norm=TwoSlopeNorm(0))\n",
    "axes[1].set_title(\"anisotropic top gradients (top to bottom)\")\n",
    "_ = axes[1].imshow(top_gradients, cmap=\"RdBu\", norm=TwoSlopeNorm(0))\n",
    "axes[2].set_title(\"normals (clipped)\")\n",
    "_ = axes[2].imshow(np.clip(normals, 0, 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heights\n",
    "\n",
    "The height values $h(x,y) \\in \\mathbb{R}^{2}, \\ \\ x,y \\in \\mathbb{N}^{0}$ can be calculated by a cumulative sum over the gradients which converges to an integral over $g(x,y)$:\n",
    "\n",
    "$$\n",
    "h(x_t,y_t) = \\iint g(x,y) dydx \\ \\ (x_t,y_t) \\approx \\sum_{x_i=0}^{x_t} g(x_i,y_t)\n",
    "$$\n",
    "\n",
    "The isotropic (non-directional) heights are determined with a combination of all anisotropic heights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_gradient_field(gradient_field: np.ndarray, axis: int) -> np.ndarray:\n",
    "    return np.cumsum(gradient_field, axis=axis)\n",
    "\n",
    "\n",
    "def calculate_heights(\n",
    "    left_gradients: np.ndarray, top_gradients: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    left_heights = integrate_gradient_field(left_gradients, axis=1)\n",
    "    right_heights = np.fliplr(\n",
    "        integrate_gradient_field(np.fliplr(-left_gradients), axis=1)\n",
    "    )\n",
    "    top_heights = integrate_gradient_field(top_gradients, axis=0)\n",
    "    bottom_heights = np.flipud(\n",
    "        integrate_gradient_field(np.flipud(-top_gradients), axis=0)\n",
    "    )\n",
    "    return left_heights, right_heights, top_heights, bottom_heights\n",
    "\n",
    "\n",
    "left_heights, right_heights, top_heights, bottom_heights = calculate_heights(\n",
    "    left_gradients, top_gradients\n",
    ")\n",
    "\n",
    "\n",
    "def combine_heights(*heights: np.ndarray) -> np.ndarray:\n",
    "    return np.mean(heights, axis=0)\n",
    "\n",
    "\n",
    "isotropic_heights = combine_heights(\n",
    "    left_heights, right_heights, top_heights, bottom_heights\n",
    ")\n",
    "\n",
    "\n",
    "def visualize_heights(heights_list: List[np.ndarray], labels: List[str]):\n",
    "    if len(heights_list) == 1:\n",
    "        heights = heights_list[0]\n",
    "        plt.title(labels[0])\n",
    "        _ = plt.imshow(heights)\n",
    "        x, y = np.meshgrid(range(heights.shape[1]), range(heights.shape[0]))\n",
    "        _, axes = plt.subplots(1, 1, subplot_kw={\"projection\": \"3d\"})\n",
    "        _ = axes.scatter(x, y, heights, c=heights)\n",
    "        return\n",
    "\n",
    "    figure, axes = plt.subplots(1, len(heights_list), figsize=(19, 5))\n",
    "    for index, heights in enumerate(heights_list):\n",
    "        axes[index].set_title(labels[index])\n",
    "        _ = axes[index].imshow(heights, norm=TwoSlopeNorm(0.5))\n",
    "\n",
    "    x, y = np.meshgrid(range(left_heights.shape[0]), range(left_heights.shape[1]))\n",
    "    figure, axes = plt.subplots(\n",
    "        1, len(heights_list), subplot_kw={\"projection\": \"3d\"}, figsize=(19, 5)\n",
    "    )\n",
    "    for index, heights in enumerate(heights_list):\n",
    "        _ = axes[index].scatter(x, y, heights, c=heights)\n",
    "\n",
    "\n",
    "visualize_heights(\n",
    "    [left_heights, right_heights, top_heights, bottom_heights, isotropic_heights],\n",
    "    [\n",
    "        \"anisotropic left heights\",\n",
    "        \"anisotropic right heights\",\n",
    "        \"anisotropic top heights\",\n",
    "        \"anisotropic bottom heights\",\n",
    "        \"isotropic heights\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation\n",
    "\n",
    "This alone is very prone for errors. That’s why rotation is introduced. When re-calculating the gradient map multiple times with a rotation factor and using that to calculate the height values for every re-calculated gradient map, adding this values together drastically improves the resulting height values:\n",
    "\n",
    "$$\n",
    "h(x_t,y_t) = \\sum_{r=0}^{2\\pi} \\sum_{x_i=0}^{x_t} g R_\\theta (x_i,y_t)\n",
    "$$\n",
    "\n",
    "If we think of the left, right, top and bottom height maps in polar coordinates, we better call them 180°, 0°, 90° and 270° height maps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.polar()\n",
    "_ = plt.yticks([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to for example calculate a 225° anisotropic height map, we need to rotate the normal map first, but a simple image-rotation will result in wrong normals. Thus, we also need to rotate the normals accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANGLE = 225\n",
    "\n",
    "\n",
    "def rotate(matrix: np.ndarray, angle: float) -> np.ndarray:\n",
    "    image_size = (matrix.shape[1], matrix.shape[0])\n",
    "    image_center = tuple(np.array(image_size) / 2)\n",
    "\n",
    "    rotation_matrix = np.matrix(\n",
    "        np.vstack([cv.getRotationMatrix2D(image_center, angle, 1.0), [0, 0, 1]])\n",
    "    )\n",
    "    translation_matrix = np.matrix(np.identity(3))\n",
    "\n",
    "    w2 = image_size[0] * 0.5\n",
    "    h2 = image_size[1] * 0.5\n",
    "\n",
    "    rot_mat_notranslate = np.matrix(rotation_matrix[0:2, 0:2])\n",
    "\n",
    "    tl = (np.array([-w2, h2]) * rot_mat_notranslate).A[0]\n",
    "    tr = (np.array([w2, h2]) * rot_mat_notranslate).A[0]\n",
    "    bl = (np.array([-w2, -h2]) * rot_mat_notranslate).A[0]\n",
    "    br = (np.array([w2, -h2]) * rot_mat_notranslate).A[0]\n",
    "\n",
    "    x_coords = [pt[0] for pt in [tl, tr, bl, br]]\n",
    "    x_pos = [x for x in x_coords if x > 0]\n",
    "    x_neg = [x for x in x_coords if x < 0]\n",
    "\n",
    "    y_coords = [pt[1] for pt in [tl, tr, bl, br]]\n",
    "    y_pos = [y for y in y_coords if y > 0]\n",
    "    y_neg = [y for y in y_coords if y < 0]\n",
    "\n",
    "    right_bound = max(x_pos)\n",
    "    left_bound = min(x_neg)\n",
    "    top_bound = max(y_pos)\n",
    "    bot_bound = min(y_neg)\n",
    "\n",
    "    new_w = int(abs(right_bound - left_bound))\n",
    "    new_h = int(abs(top_bound - bot_bound))\n",
    "    new_image_size = (new_w, new_h)\n",
    "\n",
    "    new_midx = new_w * 0.5\n",
    "    new_midy = new_h * 0.5\n",
    "\n",
    "    dx = int(new_midx - w2)\n",
    "    dy = int(new_midy - h2)\n",
    "\n",
    "    translation_matrix = np.matrix(np.array([[1, 0, dx], [0, 1, dy], [0, 0, 1]]))\n",
    "    affine_mat = (np.matrix(translation_matrix) * rotation_matrix)[0:2, :]\n",
    "    result = cv.warpAffine(matrix, affine_mat, new_image_size, flags=cv.INTER_LINEAR)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "rotated_normal_map_wrong = rotate(NORMAL_MAP_A_IMAGE, ANGLE)\n",
    "\n",
    "wrong_normals = (\n",
    "    (rotated_normal_map_wrong[:, :, :3].astype(np.float64) / 255) - 0.5\n",
    ") * 2\n",
    "\n",
    "\n",
    "def rotate_vector_field_normals(normals, angle):\n",
    "    rotated_normals = normals.copy()\n",
    "    rotated_normals[:, :, 0] = normals[:, :, 0] * cos(radians(angle))\n",
    "    rotated_normals[:, :, 0] -= normals[:, :, 1] * sin(radians(angle))\n",
    "    rotated_normals[:, :, 1] = normals[:, :, 0] * sin(radians(angle))\n",
    "    rotated_normals[:, :, 1] += normals[:, :, 1] * cos(radians(angle))\n",
    "    return rotated_normals\n",
    "\n",
    "\n",
    "rotated_normals = rotate_vector_field_normals(wrong_normals, ANGLE)\n",
    "rotated_normal_map = (((rotated_normals + 1) / 2) * 255).astype(np.uint8)\n",
    "\n",
    "figure, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "axes[0].set_title(\"normal map\")\n",
    "_ = axes[0].imshow(NORMAL_MAP_A_IMAGE)\n",
    "axes[1].set_title(\"rotated normal map (wrong)\")\n",
    "_ = axes[1].imshow(rotated_normal_map_wrong)\n",
    "axes[2].set_title(\"rotated normal map (correct)\")\n",
    "_ = axes[2].imshow(rotated_normal_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centered_crop(image: np.ndarray, target_resolution: Tuple[int, int]) -> np.ndarray:\n",
    "    return image[\n",
    "        (image.shape[0] - target_resolution[0])\n",
    "        // 2 : (image.shape[0] - target_resolution[0])\n",
    "        // 2\n",
    "        + target_resolution[0],\n",
    "        (image.shape[1] - target_resolution[1])\n",
    "        // 2 : (image.shape[1] - target_resolution[1])\n",
    "        // 2\n",
    "        + target_resolution[1],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_vector_field(\n",
    "    vector_field: np.ndarray, target_iteration_count: int\n",
    ") -> np.ndarray:\n",
    "    shape = vector_field.shape[:2]\n",
    "    angles = np.linspace(0, 90, target_iteration_count, endpoint=False)\n",
    "    thread_count = 4\n",
    "\n",
    "    def integrate_vector_field_angles(angles: List[float]) -> np.ndarray:\n",
    "        all_combined_heights = np.zeros(shape)\n",
    "\n",
    "        for angle in angles:\n",
    "            rotated_vector_field = rotate_vector_field_normals(\n",
    "                rotate(vector_field, angle), angle\n",
    "            )\n",
    "\n",
    "            left_gradients, top_gradients = calculate_gradients(rotated_vector_field)\n",
    "            (\n",
    "                left_heights,\n",
    "                right_heights,\n",
    "                top_heights,\n",
    "                bottom_heights,\n",
    "            ) = calculate_heights(left_gradients, top_gradients)\n",
    "\n",
    "            combined_heights = combine_heights(\n",
    "                left_heights, right_heights, top_heights, bottom_heights\n",
    "            )\n",
    "            combined_heights = centered_crop(rotate(combined_heights, -angle), shape)\n",
    "            all_combined_heights += combined_heights / len(angles)\n",
    "\n",
    "        return all_combined_heights\n",
    "\n",
    "    with Pool(processes=thread_count) as pool:\n",
    "        heights = pool.map(\n",
    "            integrate_vector_field_angles,\n",
    "            np.array(\n",
    "                np.array_split(angles, thread_count),\n",
    "                dtype=object,\n",
    "            ),\n",
    "        )\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "    isotropic_height = np.zeros(shape)\n",
    "    for height in heights:\n",
    "        isotropic_height += height / thread_count\n",
    "\n",
    "    return isotropic_height\n",
    "\n",
    "\n",
    "def estimate_height_map(\n",
    "    normal_map: np.ndarray, target_iteration_count: int = 250\n",
    ") -> np.ndarray:\n",
    "    normals = ((normal_map[:, :, :3] / 255) - 0.5) * 2\n",
    "    heights = integrate_vector_field(normals, target_iteration_count)\n",
    "    return heights\n",
    "\n",
    "\n",
    "figure, axes = plt.subplots(1, 4, figsize=(14, 6))\n",
    "\n",
    "for index in range(4):\n",
    "    target_iteration_count = max(1, index * 5)\n",
    "    heights = estimate_height_map(NORMAL_MAP_B_IMAGE, target_iteration_count)\n",
    "    x, y = np.meshgrid(range(heights.shape[0]), range(heights.shape[1]))\n",
    "\n",
    "    axes[index].set_title(f\"target iteration count: {target_iteration_count}\")\n",
    "    _ = axes[index].imshow(heights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = estimate_height_map(NORMAL_MAP_A_IMAGE)\n",
    "\n",
    "_ = plt.imshow(heights)\n",
    "x, y = np.meshgrid(range(heights.shape[1]), range(heights.shape[0]))\n",
    "_, axes = plt.subplots(1, 1, subplot_kw={\"projection\": \"3d\"})\n",
    "_ = axes.scatter(x, y, heights, c=heights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "## Integration\n",
    "\n",
    "Cumulative sum is a a very primitive way of calculating an integral. In the following the trapezoid and the Simpson method are implemented additionally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import auto, Enum\n",
    "\n",
    "\n",
    "class INTEGRATION_METHODS(Enum):\n",
    "    SUM = auto()\n",
    "    TRAPEZOID = auto()\n",
    "    SIMSPSON = auto()\n",
    "\n",
    "\n",
    "def integrate_gradient_field(gradient_field: np.ndarray, axis: int) -> np.ndarray:\n",
    "    if INTEGRATION_METHOD == INTEGRATION_METHOD.SUM:\n",
    "        return np.cumsum(gradient_field, axis=axis)\n",
    "\n",
    "    if INTEGRATION_METHOD == INTEGRATION_METHOD.TRAPEZOID:\n",
    "        return cumulative_trapezoid(gradient_field, axis=axis, initial=0)\n",
    "\n",
    "    if INTEGRATION_METHOD == INTEGRATION_METHOD.SIMSPSON:\n",
    "        integral = np.zeros(gradient_field.shape[:2])\n",
    "\n",
    "        if axis == 1:\n",
    "            for y in range(gradient_field.shape[0]):\n",
    "                for x in range(1, gradient_field.shape[1]):\n",
    "                    integral[y, x] = simpson(gradient_field[y, :x])\n",
    "\n",
    "        elif axis == 0:\n",
    "            for x in range(gradient_field.shape[1]):\n",
    "                for y in range(1, gradient_field.shape[0]):\n",
    "                    integral[y, x] = simpson(gradient_field[:y, x])\n",
    "\n",
    "        return integral\n",
    "\n",
    "    raise NotImplementedError(\n",
    "        f\"Integration method '{INTEGRATION_METHOD}' not implemented.\"\n",
    "    )\n",
    "\n",
    "\n",
    "target_iteration_count = 1\n",
    "\n",
    "\n",
    "INTEGRATION_METHOD = INTEGRATION_METHODS.TRAPEZOID\n",
    "trapezoid_heights = estimate_height_map(NORMAL_MAP_A_IMAGE, target_iteration_count)\n",
    "\n",
    "INTEGRATION_METHOD = INTEGRATION_METHODS.SIMSPSON\n",
    "simpson_heights = estimate_height_map(NORMAL_MAP_A_IMAGE, target_iteration_count)\n",
    "\n",
    "INTEGRATION_METHOD = INTEGRATION_METHODS.SUM\n",
    "sum_heights = estimate_height_map(NORMAL_MAP_A_IMAGE, target_iteration_count)\n",
    "\n",
    "visualize_heights(\n",
    "    [sum_heights, trapezoid_heights, simpson_heights], [\"sum\", \"trapezoid\", \"Simpson\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They all look quite the same and in fact, they are pretty much equal. However, the Simpson approach takes a very long computational time in this implementation, compared to sum and trapezoid.\n",
    "\n",
    "This is quite demotivating in regard of using polynomial approximation in general to improve the resulting heights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence\n",
    "\n",
    "A simple approach to calculate the confidence of a pixel is to override the heights combination function to return the negative standard deviation instead of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_heights(*heights: np.ndarray) -> np.ndarray:\n",
    "    return -np.std(heights, axis=0)\n",
    "\n",
    "\n",
    "confidences = estimate_height_map(NORMAL_MAP_A_IMAGE)\n",
    "plt.title(\"confidences\")\n",
    "plt.xlabel(f\"mean: {np.mean(confidences)}\")\n",
    "_ = plt.imshow(confidences)\n",
    "_ = plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "map-test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
