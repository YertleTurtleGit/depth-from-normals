{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VrhtlvFNVE6"
   },
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T12:25:53.734185Z",
     "iopub.status.busy": "2022-02-20T12:25:53.733665Z",
     "iopub.status.idle": "2022-02-20T12:25:57.190240Z",
     "shell.execute_reply": "2022-02-20T12:25:57.189495Z"
    },
    "id": "qJM0ecFCGW7m"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage import rotate\n",
    "from math import sin, cos, radians, sqrt, ceil, floor\n",
    "from os import cpu_count\n",
    "from threading import Thread\n",
    "from typing import List, Tuple\n",
    "from logging import warning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declarations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_notebook() -> bool:\n",
    "    \"\"\"Checks whether the script is started from inside a jupyter notebook.\n",
    "    From https://stackoverflow.com/questions/15411967/how-can-i-check-if-code-is-executed-in-the-ipython-notebook\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the script is started from inside a jupyter notebook.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        return True if shell == \"ZMQInteractiveShell\" else False\n",
    "    except NameError:\n",
    "        return False\n",
    "\n",
    "\n",
    "IS_NOTEBOOK: bool = is_notebook()\n",
    "PATH_PREFIX: str = (\n",
    "    \"https://raw.githubusercontent.com/YertleTurtleGit/photometric-stereo-mappings/main/test_dataset/output/\"\n",
    "    if IS_NOTEBOOK\n",
    "    else \"./../test-dataset/output/\"\n",
    ")\n",
    "NORMAL_MAP_PATH: str = PATH_PREFIX + \"normal.png\"\n",
    "MASK_PATH: str = PATH_PREFIX + \"opacity.png\"\n",
    "OUTPUT_PATH = None if IS_NOTEBOOK else PATH_PREFIX + \"./test_dataset/height_map.png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_image(\n",
    "    image_path: str, color: bool = True, target_dtype: np.dtype = np.dtype(\"float64\")\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Reads an image from URI and converts it to an array with specified bit depth.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The path to the image file.\n",
    "        color (bool, optional): Read image as color image. Defaults to True.\n",
    "        target_dtype (np.dtype, optional): The target bit depth. Defaults to np.dtype(\"float64\").\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The output array with shape (w,h,3) for color or (w,h) for grayscale images.\n",
    "    \"\"\"\n",
    "    image = io.imread(image_path)\n",
    "    image_dtype: np.dtype = image.dtype\n",
    "    image = image.astype(target_dtype)\n",
    "\n",
    "    if image_dtype == np.dtype(\"uint8\"):\n",
    "        image /= pow(2, 8) - 1\n",
    "    elif image_dtype == np.dtype(\"uint16\"):\n",
    "        image /= pow(2, 16) - 1\n",
    "    elif image_dtype == np.dtype(\"uint32\"):\n",
    "        image /= pow(2, 32) - 1\n",
    "\n",
    "    if color:\n",
    "        if len(image.shape) == 3:\n",
    "            return image\n",
    "        elif len(image.shape) == 2:\n",
    "            return np.array([image, image, image])\n",
    "        elif len(image.shape) == 4:\n",
    "            return np.array([image[:, :, 0], image[:, :, 1], image[:, :, 2]])\n",
    "        else:\n",
    "            warning(\n",
    "                \"Image channel count of \"\n",
    "                + str(len(image.shape))\n",
    "                + \" with shape \"\n",
    "                + str(image.shape)\n",
    "                + \" is unknown: \"\n",
    "                + image_path\n",
    "            )\n",
    "    else:\n",
    "        if len(image.shape) == 2:\n",
    "            return image\n",
    "        elif len(image.shape) == 3 or len(image.shape) == 4:\n",
    "            return (image[:, :, 0] + image[:, :, 1] + image[:, :, 2]) / 3\n",
    "        else:\n",
    "            warning(\n",
    "                \"Image channel count of \"\n",
    "                + str(len(image.shape))\n",
    "                + \" with shape \"\n",
    "                + str(image.shape)\n",
    "                + \" is unknown: \"\n",
    "                + image_path\n",
    "            )\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_atlas_countries(\n",
    "    mask: np.ndarray, albedo: np.ndarray\n",
    ") -> Tuple[List[np.ndarray], List[Tuple[int, int, int, int]]]:\n",
    "\n",
    "    image_parts: List[np.ndarray] = []\n",
    "    image_parts_rectangles: List[Tuple[int, int, int, int]] = []\n",
    "\n",
    "    for x in range(0, mask.shape[0]):\n",
    "        for y in range(0, mask.shape[1]):\n",
    "            if mask[x, y] > 0:\n",
    "                mask_before = mask.copy()\n",
    "                _, mask, _, rect = cv.floodFill(np.float32(mask), None, (y, x), 0)\n",
    "\n",
    "                part_albedo = albedo.copy()\n",
    "                part_albedo[mask_before == mask] = 0\n",
    "\n",
    "                r_y, r_x, r_h, r_w = rect\n",
    "                image_part = part_albedo[r_x : r_x + r_w, r_y : r_y + r_h]\n",
    "\n",
    "                image_parts.append(image_part)\n",
    "                image_parts_rectangles.append((r_x, r_y, r_w, r_h))\n",
    "\n",
    "    return image_parts, image_parts_rectangles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _integrate(\n",
    "    normal_map: np.ndarray,\n",
    "    normal_is_open_gl: bool,\n",
    "    normal_is_pseudo_compressed: bool,\n",
    "    target_iteration_count: int,\n",
    "    max_thread_count: int,\n",
    ") -> np.ndarray:\n",
    "    normal_map = normal_map.astype(\"float64\")\n",
    "\n",
    "    if normal_is_pseudo_compressed:\n",
    "        # TODO Fix line.\n",
    "        normal_map[:, :2] *= 2\n",
    "        normal_map[:, :2] -= 1\n",
    "\n",
    "    # TODO Handle non-open_gl.\n",
    "\n",
    "    SLOPE_SHIFT: float = -0.5\n",
    "    normal_map[:, :, 0][normal_map[:, :, 2] != 0] /= normal_map[:, :, 2][\n",
    "        normal_map[:, :, 2] != 0\n",
    "    ]\n",
    "    normal_map[:, :, 1][normal_map[:, :, 2] != 0] /= normal_map[:, :, 2][\n",
    "        normal_map[:, :, 2] != 0\n",
    "    ]\n",
    "    normal_map[normal_map[:, :, 2] == 0] = [0, 0, 0]\n",
    "    normal_map[normal_map[:, :, 2] != 0] += SLOPE_SHIFT\n",
    "    normal_map[:, :, 0] *= -1\n",
    "\n",
    "    n_w, n_h, _ = normal_map.shape\n",
    "\n",
    "    diagonal_length: int = ceil(sqrt(pow(n_w, 2) + pow(n_h, 2)))\n",
    "    isotropic_integral = np.zeros((diagonal_length, diagonal_length))\n",
    "\n",
    "    i_w, i_h = isotropic_integral.shape\n",
    "\n",
    "    fx: np.ndarray = np.zeros(isotropic_integral.shape)\n",
    "    fy: np.ndarray = np.zeros(isotropic_integral.shape)\n",
    "\n",
    "    fx[\n",
    "        floor((i_w - n_w) / 2) : floor((i_w + n_w) / 2),\n",
    "        floor((i_h - n_h) / 2) : floor((i_h + n_h) / 2),\n",
    "    ] = normal_map[:, :, 0]\n",
    "    fy[\n",
    "        floor((i_w - n_w) / 2) : floor((i_w + n_w) / 2),\n",
    "        floor((i_h - n_h) / 2) : floor((i_h + n_h) / 2),\n",
    "    ] = normal_map[:, :, 1]\n",
    "\n",
    "    def integrate_anisotropic(angles: List[float]):\n",
    "        for angle in angles:\n",
    "            x_factor: float = cos(radians(angle))\n",
    "            y_factor: float = sin(radians(angle))\n",
    "\n",
    "            factor_norm: float = abs(x_factor) + abs(y_factor)\n",
    "            x_factor /= factor_norm\n",
    "            y_factor /= factor_norm\n",
    "\n",
    "            fxy = fx * x_factor + fy * y_factor\n",
    "            fxy = rotate(fxy, angle, axes=(1, 0), reshape=False)\n",
    "\n",
    "            anisotropic_integral = rotate(\n",
    "                np.cumsum(fxy, axis=1), -angle, axes=(1, 0), reshape=False\n",
    "            )\n",
    "            isotropic_integral[~np.isnan(anisotropic_integral)] += anisotropic_integral[\n",
    "                ~np.isnan(anisotropic_integral)\n",
    "            ]\n",
    "\n",
    "    anisotropic_integral_threads: List[Thread] = []\n",
    "    angle_per_thread: float = 360 / max_thread_count\n",
    "    iterations_per_thread: int = round(target_iteration_count / max_thread_count)\n",
    "\n",
    "    for thread_id in range(0, max_thread_count):\n",
    "        angles = np.linspace(\n",
    "            thread_id * angle_per_thread,\n",
    "            (thread_id + 1) * angle_per_thread,\n",
    "            iterations_per_thread,\n",
    "            endpoint=False,\n",
    "        )\n",
    "        thread = Thread(target=integrate_anisotropic, args=(angles,))\n",
    "        thread.start()\n",
    "        anisotropic_integral_threads.append(thread)\n",
    "\n",
    "    for thread in anisotropic_integral_threads:\n",
    "        thread.join()\n",
    "\n",
    "    height_map = isotropic_integral[\n",
    "        floor((i_w - n_w) / 2) : floor((i_w + n_w) / 2),\n",
    "        floor((i_h - n_h) / 2) : floor((i_h + n_h) / 2),\n",
    "    ]\n",
    "\n",
    "    height_map[\n",
    "        np.sqrt(\n",
    "            np.abs(normal_map[:, :, 0])\n",
    "            + np.abs(normal_map[:, :, 1])\n",
    "            + np.abs(normal_map[:, :, 2])\n",
    "        )\n",
    "        == 0\n",
    "    ] = None\n",
    "\n",
    "    return height_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def height_map(\n",
    "    normal_map_path: str,\n",
    "    mask_path: str,\n",
    "    output_path: str = None,\n",
    "    normal_is_open_gl: bool = True,\n",
    "    normal_is_pseudo_compressed: bool = False,\n",
    "    target_iteration_count: int = 100,\n",
    "    max_thread_count: int = max(int(cpu_count() or 1), 1),\n",
    "):\n",
    "    normal_map = _read_image(normal_map_path)\n",
    "    mask = _read_image(mask_path, color=False)\n",
    "    mask[mask < 0.5] = 0\n",
    "    mask[mask >= 0.5] = 1\n",
    "\n",
    "    countries, country_bounding_boxes = _get_atlas_countries(mask, normal_map)\n",
    "\n",
    "    height_map = np.zeros((normal_map.shape[0], normal_map.shape[1]))\n",
    "\n",
    "    for i in range(0, len(countries)):\n",
    "        p_x, p_y, p_w, p_h = country_bounding_boxes[i]\n",
    "        part_height_map = _integrate(\n",
    "            countries[i],\n",
    "            normal_is_open_gl,\n",
    "            normal_is_pseudo_compressed,\n",
    "            target_iteration_count,\n",
    "            max_thread_count,\n",
    "        )\n",
    "        height_map[p_x : p_x + p_w, p_y : p_y + p_h][\n",
    "            ~np.isnan(part_height_map)\n",
    "        ] = part_height_map[~np.isnan(part_height_map)]\n",
    "\n",
    "    height_map -= np.min(height_map)\n",
    "    height_map /= np.max(height_map)\n",
    "    height_map *= pow(2, 8) - 1\n",
    "\n",
    "    if OUTPUT_PATH:\n",
    "        cv.imwrite(output_path, height_map)\n",
    "    else:\n",
    "        plt.imshow(height_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_map(NORMAL_MAP_PATH, MASK_PATH, OUTPUT_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "map-test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
